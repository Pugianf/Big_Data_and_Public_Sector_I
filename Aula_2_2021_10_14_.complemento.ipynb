{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula_2021_10_14_c.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SiL6z1iJ3cu9",
        "yQZyQey9zwLS",
        "SQnmu3J6MG2k",
        "kUnh-X4YRTyr",
        "oRhV_M_BR08q"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pugianf/Big_Data_and_Public_Sector_I/blob/main/Aula_2_2021_10_14_.complemento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lfjkPE7wVWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb55131-3d56-4fa5-8af0-6e5cc3777c05"
      },
      "source": [
        "## Importando módulos necessários\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "from zipfile import ZipFile\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxjct1edw6dL",
        "outputId": "2f3e86b5-edfe-42c0-ee18-26fb74d07463"
      },
      "source": [
        "## Montando o Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "tsZy-59IxHNR",
        "outputId": "67d65a7c-1dcd-448f-f863-fce63413e332"
      },
      "source": [
        "## Lendo os arquivos\n",
        "# Determinando o Caminho\n",
        "sCaminho = '/content/drive/MyDrive/'\n",
        "\n",
        "## Lendo o arquivo zipado\n",
        "# Leitura feita no R e dados já filtrados para NaNs de renda e para apenas pessoas em idade ativa\n",
        "http =\"https://github.com/claudiomar23/Python_open_class/blob/main/PNADC_042019.zip?raw=true\"\n",
        "\n",
        "sArquivo = f\"{sCaminho}PNADC_042019.zip\"\n",
        "with ZipFile(sArquivo) as z:\n",
        "    df = pd.read_csv(z.open(http))\n",
        "    print(*z.namelist(),sep=\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-b4fe63346c5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msArquivo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{sCaminho}PNADC_042019.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msArquivo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, name, mode, pwd, force_zip64)\u001b[0m\n\u001b[1;32m   1501\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m             \u001b[0;31m# Get info object for name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1503\u001b[0;31m             \u001b[0mzinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36mgetinfo\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1429\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m             raise KeyError(\n\u001b[0;32m-> 1431\u001b[0;31m                 'There is no item named %r in the archive' % name)\n\u001b[0m\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"There is no item named 'https://github.com/claudiomar23/Python_open_class/blob/main/PNADC_042019.zip?raw=true' in the archive\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s52srJXf8ErO"
      },
      "source": [
        "## Importante: os valores nulos de renda (VD4020) não são pessoas que ganham 0; são pessoas que NÃO TRABALHAM\n",
        "# Para retirar essas pessoas da base original, \n",
        "df.dropna(subset=['VD4020'], inplace=True)\n",
        "\n",
        "## Retirando pessoas em idade não-ativa\n",
        "df = df.loc[(df[\"V2009\"] >= 15) & (df[\"V2009\"] <= 65)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN43LVUr2ksR"
      },
      "source": [
        "## Vendo o tamanho da base (lembrando que ela já está filtrada)\n",
        "print(f\"Linhas: {df.shape[0]}; Colunas: {df.shape[1]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUvPEPVL7Wcn"
      },
      "source": [
        "## Filtrando apenas para o Centro-Oeste\n",
        "df = df.loc[df[\"UF\"].isin([50, 51, 52, 53])]\n",
        "print(f\"Linhas: {df.shape[0]}; Colunas: {df.shape[1]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUfk6MQqztZn"
      },
      "source": [
        "## Preparação da base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdKc2dUsx8YV"
      },
      "source": [
        "## Criando a coluna de identificação dos domicilios\n",
        "df['iddom'] = df['UPA'].astype(str) + df['V1008'].astype(str) + df['V1014'].astype(str)\n",
        "df['idind'] = df['iddom'] + df['V2003'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7bAbbJZyF3J"
      },
      "source": [
        "## Criando idade e idade ao quadrado\n",
        "df.rename(columns={\"V2009\":\"idade\"}, inplace=True)\n",
        "df['idadesq'] = df['idade'] ** 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_CyYBfbyLTC"
      },
      "source": [
        "## Gênero (dummy feminina, mais especificamente)\n",
        "df['feminino'] = df['V2007'] - 1\n",
        "\n",
        "## Alternativamente\n",
        "# df['feminino'] = df[\"V2007\"].apply(lambda i: 1 if i == 2 else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaOrLgx7yQYp"
      },
      "source": [
        "## V2010: cor\n",
        "# Substituindo os números pelo nomes e vendo a quantidade\n",
        "df[\"V2010\"].replace([1,2,3,4,5,9], ['branca','preta','amarela','parda','indigena',np.nan], inplace=True)\n",
        "df['V2010'].value_counts(dropna=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlYXmSWwyplS"
      },
      "source": [
        "## Renomeando cor\n",
        "df.rename(columns={\"V2010\":\"cor\"}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFkmXhrzyupp"
      },
      "source": [
        "## criando as dummies e juntando-as ao dataframe\n",
        "df = pd.concat([df, pd.get_dummies(df['cor'])], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du8F83gzGbam"
      },
      "source": [
        "## Vendo se está tudo ok\n",
        "df[['cor', 'branca','preta','amarela','parda','indigena']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXtdEfpKy4-b"
      },
      "source": [
        "## Grau de Educação\n",
        "# Substituindo os números pelo nomes e vendo a quantidade\n",
        "df[\"VD3004\"].replace([1,2,3,4,5,6,7], ['sem_instrucao','fund_incompleto','fund_completo','medio_incompleto','medio_completo','superior_incompleto','superior_completo'], inplace= True)\n",
        "df['VD3004'].value_counts(normalize=True, dropna=False)*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBYw1NffzGuP"
      },
      "source": [
        "## criando as dummies e juntando-as ao dataframe\n",
        "df = pd.concat([df, pd.get_dummies(df['VD3004'])], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIQa9Ce4zUeE"
      },
      "source": [
        "## V1022: domicilios rurais\n",
        "df['rural'] = df['V1022'] - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNsuxxLXIM-y"
      },
      "source": [
        "## Vendo proporções\n",
        "df['rural'].value_counts(normalize=True, dropna=False)*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txJWTRaKzYrM"
      },
      "source": [
        "## VD4001: força de trabalho (mais especificamente, fora dela)\n",
        "df['VD4001'] = df['VD4001'] - 1\n",
        "\n",
        "## VD4002: ocupação (mais especificamente, pessoas desocupadas)\n",
        "df['VD4002'] = df['VD4002'] - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiB2YQ7PzgTt"
      },
      "source": [
        "#### dummies de ocupação ######\n",
        "## tipo de trabalho\n",
        "# mais agregado\n",
        "df['VD4008'].replace([1,2,3,4,5,6], ['privado','domestico','publico','empregador','conta_propria','familiar'], inplace=True)\n",
        "df = pd.concat([df,pd.get_dummies(df['VD4008'])], axis = 1)\n",
        "df = df.drop(['conta_propria','familiar'], axis = 1)\n",
        "\n",
        "# desagregado\n",
        "df[\"VD4009\"].replace([1,2,3,4,5,6,7,8,9,10], ['privado_formal','privado_informal','domestico_formal','domestico_informal','publico_formal','publico_informal','militar','empregador1','conta_propria','familiar'], inplace= True)\n",
        "df = pd.concat([df,pd.get_dummies(df['VD4009'])], axis = 1)\n",
        "\n",
        "## setor de ocupação\n",
        "df['VD4010'] = df['VD4010'].replace([1,2,3,4,5,6,7,8,9,10,11,12], ['agro','industria','construcao','comercio','transporte','aloj_alim','servicos','adm_publica','educ_saude','outros_servicos','servicos_domesticos','ativ_mal_definidas'])\n",
        "df = pd.concat([df,pd.get_dummies(df['VD4010'])], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2juyBjUc4I_p"
      },
      "source": [
        "## Renomendo educação\n",
        "df.rename(columns={\"VD3005\":\"educ\",\"VD3004\":\"grau_educ\"}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoKVpoYp3FaB"
      },
      "source": [
        "# Análises de Renda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp4vpGh5AxDl"
      },
      "source": [
        "Qual variável de renda usar?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEzdaqwRAg6j"
      },
      "source": [
        "## Vamos usar renda habitual total controlada por horas, por dois motivos:\n",
        "# 1. Não há nenhum caso em que a renda habitual seja 0, o que facilita a logaritimização e linearização do modelo\n",
        "# 2. Menos sensível à sazonalidade (fim de ano costuma ter mais renda efetiva em virtude de bônus e contratações temporárias)\n",
        "\n",
        "# Renomeando as rendas\n",
        "nomes_renda = {'VD4016':'renda_hab_prin','VD4017':'renda_efet_prin','VD4019':'renda_hab_tot','VD4020':'renda_efet_tot','VD4031':'horas_hab_tot','VD4032':'horas_efet_prin','VD4035':'horas_efet_tot'}\n",
        "df.rename(columns = nomes_renda, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4LNRY97AgTV"
      },
      "source": [
        "## ATENÇÃO: O PAINEL SÓ CONTÉM DADOS DE RENDIMENTOS DO TRABALHO (sem benefícios previdenciários)\n",
        "## Vendo estatísticas das diferentes rendas e horas trabalhadas\n",
        "df[['renda_hab_tot','renda_hab_prin','renda_efet_tot','renda_efet_prin','horas_hab_tot','horas_efet_tot']].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtPBqPaRKZT2"
      },
      "source": [
        "## Para controlar para a oferta de horas de trabalho (mulheres ofertam menos horas)\n",
        "# dividimos pelo número de horas trabalhadas, o que é mais um motivo para usar rendas habituais\n",
        "# (rendas efetivas possuem alguns 0, o que causaria problemas de divisão)\n",
        "\n",
        "df['renda_hab_hora'] = df['renda_hab_tot']/(df['horas_hab_tot']*4)\n",
        "df['lsalariohora'] = np.log(df['renda_hab_hora'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiL6z1iJ3cu9"
      },
      "source": [
        "## Médias de renda por gênero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyQr4Ieq4ICm"
      },
      "source": [
        "## Média por gênero\n",
        "df.groupby('feminino')['renda_hab_tot'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1F_K_BZ3gCF"
      },
      "source": [
        "from scipy import stats\n",
        "\n",
        "## Subamostra de homens\n",
        "vRendaHomens = df['renda_hab_tot'].loc[df['feminino'] == 0]\n",
        "\n",
        "## Subamostra de mulheres\n",
        "vRendaMulheres = df['renda_hab_tot'].loc[df['feminino'] == 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sWOBU_-LlT0"
      },
      "source": [
        "## Teste\n",
        "stats.ttest_ind(vRendaHomens, vRendaMulheres, nan_policy='omit')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQZyQey9zwLS"
      },
      "source": [
        "## Renda por Raça"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnrrgdPBzNHL"
      },
      "source": [
        "# Média por cor\n",
        "\n",
        "df.groupby('cor')['renda_hab_tot'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63kggkqAzuNI"
      },
      "source": [
        "## Subamostra de amarelos\n",
        "vRendaAmarela = df['renda_hab_tot'].loc[df['cor'] == 'amarela']\n",
        "\n",
        "## Subamostra de branca\n",
        "vRendaBranca = df['renda_hab_tot'].loc[df['cor'] == 'branca']\n",
        "\n",
        "## Subamostra de indígena\n",
        "vRendaBranca = df['renda_hab_tot'].loc[df['cor'] == 'indígena']\n",
        "\n",
        "## Subamostra de parda\n",
        "vRendaBranca = df['renda_hab_tot'].loc[df['cor'] == 'parda']\n",
        "\n",
        "## Subamostra de preta\n",
        "vRendaBranca = df['renda_hab_tot'].loc[df['cor'] == 'preta']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQnmu3J6MG2k"
      },
      "source": [
        "## Vimos que há uma clara disparidade de gênero e raça no salário, mas como medir isso mais precisamente?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoKxqoyTLy_y"
      },
      "source": [
        "## Importando o módulo e definindo uma função\n",
        "from statsmodels.formula.api import ols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mvMRwISSBCu"
      },
      "source": [
        "## Criando fórmula\n",
        "formula = \"lsalariohora ~ feminino\"\n",
        "\n",
        "## Modelo\n",
        "mod = ols(formula, df).fit(use_t=True)\n",
        "\n",
        "## Vendo os resultados\n",
        "print(mod.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6mI4lcQSu0S"
      },
      "source": [
        "## Modelo mais completo com educ, idade, gênero e disparidades raciais\n",
        "formula = \"lsalariohora ~ educ + idade + feminino + preta + parda + amarela + indigena\"\n",
        "mod = ols(formula, df).fit(use_t=True)\n",
        "\n",
        "## Vendo os resultados\n",
        "print(mod.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgHu6XBfRIrS"
      },
      "source": [
        "## Teste t\n",
        "H0 = \"preta = 0\"\n",
        "mod.wald_test(H0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnaQ846DRnlv"
      },
      "source": [
        "## Teste F\n",
        "H0 = \"educ = idade = 0\"\n",
        "mod.wald_test(H0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqSKI1KcSBZE"
      },
      "source": [
        "## Modelo mais completo com educ, educ2, idade, idade2, gênero e disparidades raciais\n",
        "\"\"\"\n",
        "df['educsq'] = df['educ']**2\n",
        "formula = \"lsalariohora ~ educ + educsq + idade + idadesq + feminino + preta + parda + amarela + indigena\"\n",
        "mod = ols(formula, df).fit(use_t=True)\n",
        "\n",
        "## Vendo os resultados\n",
        "print(mod.summary())\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUnh-X4YRTyr"
      },
      "source": [
        "## Pressupostos do Modelo (Hipóteses de Gauss-Markov)\n",
        "\n",
        "1. Linearidade nos parâmetros (temos);\n",
        "\n",
        "2. Amostra aleatória (temos?);\n",
        "\n",
        "-> Os resultados de MQO podem ser atribuídos para a **amostra**, mas, na PNADC e em outras pesquisas amostrais, deve-se usar pesos para generalizar os resultados\n",
        "\n",
        "3. Colinearidade não-perfeita (nenhuma variável é função perfeita da outra; temos);\n",
        "\n",
        " -> Importância de retirar uma dummy!\n",
        "\n",
        "4. **MÉDIA CONDICIONAL 0**\n",
        "\n",
        "Não há **nenhum fator** relegado ao termo de erro que é correlacionado com algumas das variáveis tidas como exógenas (problema clássico: educ e aptidão).\n",
        "Na prática, essa hipótese é muito forte; em grandes amostras, é possível usar propriedades assintóticas do estimador de MQO e testar a **consistência** do estimador, ou seja, cov(x_j, u) = 0 para todos x_j regressores.\n",
        "\n",
        "As quatro hipóteses acima garantem a consistência de MQO, ou seja, estimativas centrais precisas.\n",
        "\n",
        "5. **Homoscedasticidade**\n",
        "\n",
        "Nome assustador para dizer algo simples: a variância do erro independe das características individuais (sob essa hipótese, pessoas mais ricas tem que ter a mesma variação de aptidão que pessoas com menos renda).\n",
        "\n",
        "Essa hipótese permite calcular os erros-padrão dos estimadores e encontrar intervalos de confiança estatisticamente corretos para os parâmetros.\n",
        "\n",
        "As 5 hipóteses acima são as **Hipóteses de Gauss-Markov**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C22FVkJfZMYd"
      },
      "source": [
        "## Caso o import abaixo dê erro, rodar (demora um pouquinho):\n",
        "# ! pip install --upgrade Cython\n",
        "# ! pip install --upgrade git+https://github.com/statsmodels/statsmodels\n",
        "# import statsmodels.api as sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fAFKgK60Y_Wg"
      },
      "source": [
        "## Testando a hipótese 4: teste RESET\n",
        "from statsmodels.stats.diagnostic import het_breuschpagan, linear_reset\n",
        "\n",
        "def reset_ols(formula, data, cov='normal', level=0.05):\n",
        "    \"\"\"\n",
        "    Executes a RESET test for a OLS model specification, where H0: model is well specified\n",
        "    It is not necessary to assign the function to an object!\n",
        "\n",
        "    :param formula : patsy formula\n",
        "    :param data : dataframe\n",
        "    :param cov : str\n",
        "        normal: common standard errors\n",
        "        robust: HC1 standard errors\n",
        "    :param level : significance level (default 5%)\n",
        "    \"\"\"\n",
        "    ## getting covariance type\n",
        "    if cov == 'normal':\n",
        "        cov_type = 'nonrobust'\n",
        "    else:\n",
        "        cov_type = 'HC1'\n",
        "\n",
        "    ## OLS model \n",
        "    mod = ols(formula=formula, data=data).fit(use_t=True, cov_type=cov_type)\n",
        "\n",
        "    ## executing test\n",
        "    test = linear_reset(mod, power=3, use_f=False, cov_type=cov_type)\n",
        "    if test.pvalue < level:\n",
        "        print(f\"The test's p-value is equal to {np.around(test.pvalue, 6)} < {level * 100}%\")\n",
        "        print(\"Therefore, Ho is rejected (the model is badly specified).\")\n",
        "    else:\n",
        "        print(f\"The test's p-value is equal to {np.around(test.pvalue, 6)} > {level * 100}%\")\n",
        "        print(\"Therefore, Ho is NOT rejected (the model is not badly specified).\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K-uFjgYsZCJX"
      },
      "source": [
        "reset_ols(formula, df, cov='robust')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "elKI_OKdRVwa"
      },
      "source": [
        "## Testando a hipótese 5: breusch-pagan!\n",
        "from statsmodels.compat import lzip\n",
        "\n",
        "lNomesBP = ['Multiplicador de Lagrange', 'P-valor', 'Estatística F', 'P-valor F']\n",
        "lTestBP = het_breuschpagan(mod.resid, mod.model.exog)\n",
        "lzip(lNomesBP, lTestBP)\n",
        "\n",
        "# Resultado: com certeza há heteroscedasticidade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRhV_M_BR08q"
      },
      "source": [
        "## Como consertar heteroscedasticidade?\n",
        "\n",
        "1. Se você conhecer a forma da heteroscedasticidade (muito difícil)\n",
        "Casos clássicos: se, ao invés de dados individuais, possuirmos apenas dados médios de algum grupo ou região geográfica; modelo de probabilidade linear (para uma discussão muito boa e inteligível, ver Introdução à Econometria do Wooldridge, Seções 8.4 até o fim do capítulo 8)\n",
        "\n",
        "2. Usar erros padrão robusto! Em python, eles são tidos como HC1 (iguais à opção *robust* no STATA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE7fTm3xR6W6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}